---
title: "The pitfalls of performance measurement"
category: [blog]
tag: 'digital transformation'
author: 
author-excerpt: "at the Digital Transformation Agency." 
thumbnail: /images/blog-thumbnails/cloud_thumb.png
hero-image: /images/blog-content/Cloud_hero.png
searchexcerpt: "Measuring performance is pretty much a part of the workplace psyche these days, but do we take it for granted? Do we really understand why itâ€™s important? "
---

The DTAâ€™s Performance Dashboard is all about measurement, but it is important that the right things are measured at the right time â€” that product teams identify early in the process what metrics will show them how well they have met their users needs. 

This goes to the heart of why the DTA has developed the Performance Dashboard. Itâ€™s a central platform for all levels of government to share information and to facilitate improved transparency within agencies and to the general public.
 
Itâ€™s an opportunity for agencies to demonstrate how well they are meeting usersâ€™ needs and look for opportunities to continually improve performance. It also provides a visual platform for people to monitor performance so that mistakes like the bridges that donâ€™t meet in the middle (see the above photograph) donâ€™t happen. But this begs the question: how can problems like that eventuate? 

The team behind the Dashboard have spent some time considering the pitfalls you should avoid if you want performance measurement to be effective.

While there is plenty of speculation regarding the authenticity of the photo of the bridges that didnâ€™t meet, there is no questioning the fact that something went horribly wrong. It would seem pretty clear that performance against a reasonably obvious objective, â€˜make sure the two ends of the bridge meetâ€™, either wasnâ€™t measured or wasnâ€™t measured well.

The same thing can happen in your workplace. Imagine the following scenario. 

Thereâ€™s a problem with your service. Your team needs to fix the problem, and it needs to happen yesterday. No time to waste, the team springs into action and fixes it. You all think itâ€™s great. Well done team, weâ€™re awesome! Except, it doesnâ€™t make the user experience better, it might have actually made it worse.

Confusion reigns.

The following emojis appear ðŸ˜¨ðŸ˜–ðŸ˜¨ðŸ˜¢ðŸ˜¬.

What went wrong? A few basic things...

The team didnâ€™t take the time to understand the problem in terms of the user need. They didnâ€™t set clear goals about what they wanted to achieve. And, they didnâ€™t develop any measures they could use to demonstrate whether they were achieving their goals. 

There is already too much to do, and setting up performance measures early can be sent to the bottom of a long to do list, to often not get done. Not only is this a risky approach, itâ€™s an approach that means the intrinsic value of knowing how well, or not, you are travelling is completely lost. 

So, on the basis that we agree that performance measurement is a valuable tool for improvement, why are teams unsuccessful in their attempts to utilise it? 

There are some common pitfalls that need to be front and centre in your thinking when trying to identify performance metrics. Hereâ€™s our top 5 list (in no particular order) of things that need to be considered if performance measurement is going to be successful.

1. Be clear what the purpose of the performance metrics is. This will help foster a common understanding and avoid data being interpreted as something that it is not. This should extend to what the consequence of poor results against the metrics might be. Is it an opportunity to improve or reason to pivot?

2. Make sure the metrics reflect real goals that are trying to be achieved. Remember that they are supposed to be KEY Performance Indicators, not superfluous vanity metrics.

3. The metrics need to be objectively measured. Itâ€™s no good having the worldâ€™s greatest metrics if you havenâ€™t built mechanisms to capture them. And as much as possible try to avoid metrics that require some kind of subjective calculation.

4. Your performance metrics should be a fundamental tool for improvement, not an added extra. If you donâ€™t develop performance metrics early you miss out on the biggest benefits they can offer. 

5. Keep testing to make sure you are building the right things. Itâ€™s easy to be lulled into a false sense of security knowing that you have metrics and you are measuring them. Stay user centered and keep iterating. Donâ€™t be the person responsible for the two bridges that donâ€™t meet!
