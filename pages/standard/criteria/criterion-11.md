---
layout: criteria
criteria-number: 11
title: Measure performance
lede: Measure performance against KPIs set out in the guides. Report on public dashboard.
permalink: /standard/11-measure-performance/
breadcrumb: 11. Measure performance
---

## Why it’s in the Standard

Every service must aim for continuous improvement. Metrics are an important starting point for discussions about a service’s strengths and weaknesses. By [identifying and capturing the right metrics](/standard/measuring-performance/) - with the right tools - you can make sure all your decisions to improve the service are supported by data.

### Key performance indicators

All services must, at a minimum, measure 4 KPIs.

- **User satisfaction** - to help continually improve the user experience of your service
- **Digital take-up** - to show how many people are using the service and to help encourage users to choose the digital service 
- **Completion rate** - to show which parts of the service you need to fix
- **Cost per transaction** - to make your service more cost efficient

There will be other metrics your service needs to measure and monitor to understand how it is performing, such as:

- error rates
- time to completion
- costs, benefits and return on investment
- content metrics (readability, length).

### Dashboard

The [Performance Dashboard](/what-we-do/platforms/performance/) collects service data and presents it in a consistent and structured format. This is important so that you can:

- make quick data-driven decisions about how to improve your service
- compare data across multiple government services
- be open and transparent to the public about your service’s performance.

## How you’ll be assessed

You’ll have started early measurement activity during [Discovery](/standard/service-design-and-delivery-process/discovery/) with your user research dashboard. 

You will need to consider how you’ll measure your service in more detail as you enter Alpha. By the end of Alpha you should have:

- explored the data that is already available for an existing service, where it is kept and how you might access and use it, and also shared your own insights
- collected baseline data for the service operation in all of its channels
- estimated the number of people you expect to use the service
- started creating a performance framework outlining your objectives and what metrics your team will use to demonstrate you meet them  
- considered the metrics you will need to [measure the 4 KPIs](/standard/measuring-performance/) and where the data will come from.

By the end of Beta you will be able to show:

- which metrics and measurements you will use to monitor your KPIs
- the baseline measures and the benchmarks for success
- that the team is ready to report their performance on the [Performance Dashboard](/our-work/performance/)
- which tools you use for analysis and web analytics in Beta (and Alpha if appropriate)
- what you have learned from qualitative and quantitative data; for example key evidence.

During the public Beta stage you’ll have been able to test your methods for data collection, validated that the data is accurate, and published service performance data on the Performance Dashboard.

As you go live you should be able to show service data on the Performance Dashboard and improvement to the service based on performance data.

Your data should show:

- user satisfaction has increased
- digital take-up is increasing in line with service plans
- completion rate has been maintained
- cost per transaction is decreasing in line with service plans.

## Guidance related to this criterion
[Measuring service performance](/standard/measuring-performance/)

## Further reading  
- [Usability.gov - Benefits of User-centered Design](http://www.usability.gov/what-and-why/benefits-of-ucd.html) 
- [GDS - Measuring success](https://www.gov.uk/service-manual/measuring-success)
- [GDS - Performance dashboards](https://www.gov.uk/performance)
- [18F - Dashboard](https://analytics.usa.gov/)
- [DTA Blog - Performance Dashboard – Practising what we preach] (https://www.dta.gov.au/blog/dashboard-practising-what-we-preach/)

**Last updated**: 22 February 2017
